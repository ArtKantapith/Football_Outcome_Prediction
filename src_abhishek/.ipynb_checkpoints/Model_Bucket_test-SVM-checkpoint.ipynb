{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "(15965L, 649L)\n",
      "(12772L, 648L)\n",
      "(0L, 648L)\n",
      "(3193L, 648L)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "\n",
    "features = 'potential,attacking_work_rate,defensive_work_rate,crossing,finishing,heading_accuracy,short_passing,volleys,dribbling,curve,free_kick_accuracy,long_passing,ball_control,acceleration,sprint_speed,agility,reactions,balance,shot_power,jumping,stamina,strength,long_shots,aggression,interceptions,positioning,vision,penalties,marking,standing_tackle,sliding_tackle,gk_diving,gk_handling,gk_kicking,gk_positioning,gk_reflexes'\n",
    "features_list = features.split(',')\n",
    "num_features = len(features_list)\n",
    "features_list = features_list * 30\n",
    "\n",
    "print(len(features_list))\n",
    "k=0\n",
    "for bucket_id in range(30):\n",
    "    idx = bucket_id  * num_features\n",
    "    for feature in features_list[ bucket_id  * num_features :  (bucket_id + 1 ) * num_features]:\n",
    "\n",
    "        features_list[idx] = str(bucket_id) + \"_\" + features_list[idx]\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=0, seed=100):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.ix[perm[:train_end]]\n",
    "    validate = df.ix[perm[train_end:validate_end]]\n",
    "    test = df.ix[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "outfile = 'alldata_buckets_4x3.npz'\n",
    "npzfile = np.load(outfile)\n",
    "\n",
    "all_data = npzfile['arr_0']\n",
    "print(all_data.shape)\n",
    "\n",
    "train_data, validate_data, test_data = train_validate_test_split(pd.DataFrame(all_data))\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "validate_data = np.array(validate_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "\n",
    "train_X = train_data[:, :-1]\n",
    "validate_X = validate_data[:, :-1]\n",
    "test_X = test_data[:, :-1]\n",
    "train_Y = train_data[:,-1]\n",
    "validate_Y = validate_data[:,-1]\n",
    "test_Y = test_data[:,-1]\n",
    "print(train_X.shape)\n",
    "print(validate_X.shape)\n",
    "print(test_X.shape)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_X = sc.fit_transform(train_X)\n",
    "test_X = sc.transform(test_X)\n",
    "epsilon = 1e-12\n",
    "mean_train = np.mean(train_X, axis = 0)\n",
    "std_train = np.std(train_X, axis = 0) + epsilon\n",
    "\n",
    "test_X = (test_X - mean_train)/std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(train_X, train_Y) \n",
    "Y_pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710616974632\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "print(sklearn.metrics.accuracy_score(test_Y, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.64      0.48      0.55      1169\n",
      "        1.0       0.74      0.84      0.79      2024\n",
      "\n",
      "avg / total       0.70      0.71      0.70      3193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(sklearn.metrics.classification_report(test_Y, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66170475255023542"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(test_Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28938302536799243"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "zero_one_loss(test_Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.70036015796563311, 0.70372690259943627)\n",
      "(1.25, 0.70122161315583398, 0.70404008769182591)\n",
      "(1.5, 0.70090837901331238, 0.70372690259943627)\n",
      "(1.75, 0.7005169895808272, 0.70372690259943627)\n",
      "(2.0, 0.70051695893169375, 0.70341371750704662)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "C = np.linspace( 1, 2, 5)\n",
    "test_scores = np.zeros(10)\n",
    "scores = np.zeros(10)\n",
    "for (i,c) in enumerate(C):\n",
    "    log = LogisticRegression(C = c,penalty='l1')\n",
    "    cross = cross_val_score(log,train_X,train_Y,cv = 5)\n",
    "    scores[i] = np.mean(cross)\n",
    "    log2 = LogisticRegression(C = c,penalty = \"l1\")\n",
    "    log2.fit(train_X,train_Y)\n",
    "    test_scores[i] = log2.score(test_X,test_Y)\n",
    "    print (c, scores[i],test_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestc = C[np.argmax(scores)]\n",
    "log = LogisticRegression(C = bestc,penalty = \"l1\")\n",
    "log.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log.score(test_X,test_y)\n",
    "plt.plot(test_scores, C)\n",
    "plt.plot(train_scores, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the iris datasets\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(train_X, train_Y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
