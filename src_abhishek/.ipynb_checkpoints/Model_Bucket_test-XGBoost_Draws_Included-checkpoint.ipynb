{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "(15965L, 865L)\n",
      "(12772L, 864L)\n",
      "(0L, 864L)\n",
      "(3193L, 864L)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "\n",
    "features = 'potential,attacking_work_rate,defensive_work_rate,crossing,finishing,heading_accuracy,short_passing,volleys,dribbling,curve,free_kick_accuracy,long_passing,ball_control,acceleration,sprint_speed,agility,reactions,balance,shot_power,jumping,stamina,strength,long_shots,aggression,interceptions,positioning,vision,penalties,marking,standing_tackle,sliding_tackle,gk_diving,gk_handling,gk_kicking,gk_positioning,gk_reflexes'\n",
    "features_list = features.split(',')\n",
    "num_features = len(features_list)\n",
    "features_list = features_list * 30\n",
    "\n",
    "print(len(features_list))\n",
    "k=0\n",
    "for bucket_id in range(30):\n",
    "    idx = bucket_id  * num_features\n",
    "    for feature in features_list[ bucket_id  * num_features :  (bucket_id + 1 ) * num_features]:\n",
    "\n",
    "        features_list[idx] = str(bucket_id) + \"_\" + features_list[idx]\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=0, seed=100):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.ix[perm[:train_end]]\n",
    "    validate = df.ix[perm[train_end:validate_end]]\n",
    "    test = df.ix[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "outfile = 'alldata_buckets_3x3.npz'\n",
    "npzfile = np.load(outfile)\n",
    "\n",
    "all_data = npzfile['arr_0']\n",
    "print(all_data.shape)\n",
    "\n",
    "train_data, validate_data, test_data = train_validate_test_split(pd.DataFrame(all_data))\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "validate_data = np.array(validate_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "\n",
    "train_X = train_data[:, :-1]\n",
    "validate_X = validate_data[:, :-1]\n",
    "test_X = test_data[:, :-1]\n",
    "train_Y = train_data[:,-1]\n",
    "validate_Y = validate_data[:,-1]\n",
    "test_Y = test_data[:,-1]\n",
    "print(train_X.shape)\n",
    "print(validate_X.shape)\n",
    "print(test_X.shape)\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_X = sc.fit_transform(train_X)\n",
    "test_X = sc.transform(test_X)\n",
    "epsilon = 1e-12\n",
    "mean_train = np.mean(train_X, axis = 0)\n",
    "std_train = np.std(train_X, axis = 0) + epsilon\n",
    "\n",
    "test_X = (test_X - mean_train)/std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(train_X, train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFdCAYAAAA+KAajAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCRJaub/BzcIoqyHbp6nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4509898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01154401  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.001443    0.          0.          0.001443    0.002886    0.\n",
      "  0.001443    0.          0.001443    0.          0.          0.001443    0.\n",
      "  0.          0.001443    0.          0.001443    0.001443    0.          0.\n",
      "  0.          0.          0.          0.00577201  0.004329    0.01154401\n",
      "  0.00721501  0.002886    0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.002886    0.          0.\n",
      "  0.          0.          0.001443    0.00577201  0.          0.00721501\n",
      "  0.001443    0.          0.          0.001443    0.          0.001443\n",
      "  0.002886    0.004329    0.001443    0.          0.001443    0.          0.\n",
      "  0.004329    0.001443    0.          0.001443    0.001443    0.001443\n",
      "  0.002886    0.01010101  0.002886    0.001443    0.          0.          0.\n",
      "  0.          0.001443    0.          0.          0.          0.          0.002886\n",
      "  0.002886    0.          0.002886    0.          0.          0.00577201\n",
      "  0.          0.          0.          0.          0.004329    0.001443    0.\n",
      "  0.          0.          0.          0.002886    0.          0.00721501\n",
      "  0.          0.          0.002886    0.01010101  0.001443    0.001443\n",
      "  0.001443    0.          0.          0.          0.          0.001443    0.\n",
      "  0.          0.          0.001443    0.00577201  0.01298701  0.          0.\n",
      "  0.001443    0.001443    0.          0.          0.          0.          0.\n",
      "  0.002886    0.002886    0.001443    0.          0.001443    0.          0.001443\n",
      "  0.002886    0.00865801  0.001443    0.001443    0.          0.01010101\n",
      "  0.00721501  0.001443    0.          0.          0.          0.002886\n",
      "  0.002886    0.          0.          0.          0.          0.          0.\n",
      "  0.00577201  0.001443    0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.004329    0.001443    0.          0.\n",
      "  0.          0.          0.          0.001443    0.001443    0.00721501\n",
      "  0.          0.          0.          0.          0.          0.001443    0.\n",
      "  0.          0.          0.          0.00577201  0.          0.          0.\n",
      "  0.002886    0.          0.00721501  0.          0.          0.002886    0.\n",
      "  0.00721501  0.002886    0.          0.          0.          0.00721501\n",
      "  0.001443    0.004329    0.          0.001443    0.          0.          0.\n",
      "  0.001443    0.00721501  0.00721501  0.004329    0.          0.          0.\n",
      "  0.001443    0.001443    0.00577201  0.001443    0.002886    0.00577201\n",
      "  0.          0.          0.001443    0.          0.          0.01875902\n",
      "  0.          0.          0.          0.001443    0.002886    0.00721501\n",
      "  0.001443    0.001443    0.          0.002886    0.          0.001443\n",
      "  0.001443    0.          0.          0.          0.          0.          0.001443\n",
      "  0.002886    0.00865801  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.001443\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.001443    0.002886    0.\n",
      "  0.001443    0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.00577201  0.          0.\n",
      "  0.          0.002886    0.001443    0.002886    0.01010101  0.001443    0.\n",
      "  0.          0.001443    0.001443    0.          0.          0.001443    0.\n",
      "  0.          0.002886    0.002886    0.          0.          0.001443    0.\n",
      "  0.          0.002886    0.00721501  0.          0.          0.          0.\n",
      "  0.004329    0.002886    0.          0.          0.          0.001443    0.\n",
      "  0.          0.          0.002886    0.          0.001443    0.00721501\n",
      "  0.          0.          0.          0.          0.001443    0.          0.\n",
      "  0.002886    0.001443    0.          0.001443    0.002886    0.          0.\n",
      "  0.          0.          0.          0.004329    0.01298701  0.001443    0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.002886    0.          0.          0.          0.          0.          0.\n",
      "  0.001443    0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.004329    0.          0.001443    0.          0.\n",
      "  0.002886    0.          0.          0.001443    0.          0.          0.001443\n",
      "  0.          0.          0.          0.00577201  0.00577201  0.001443\n",
      "  0.01587302  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.00865801  0.          0.\n",
      "  0.00721501  0.          0.004329    0.004329    0.          0.          0.002886\n",
      "  0.          0.001443    0.          0.          0.          0.001443\n",
      "  0.002886    0.          0.          0.          0.          0.002886    0.\n",
      "  0.          0.001443    0.001443    0.001443    0.004329    0.00721501\n",
      "  0.          0.          0.          0.          0.001443    0.          0.002886\n",
      "  0.01443001  0.          0.          0.          0.001443    0.00577201\n",
      "  0.001443    0.          0.          0.002886    0.          0.001443\n",
      "  0.004329    0.001443    0.          0.002886    0.004329    0.          0.\n",
      "  0.          0.004329    0.          0.          0.          0.00865801\n",
      "  0.001443    0.          0.001443    0.004329    0.004329    0.00865801\n",
      "  0.          0.001443    0.002886    0.          0.          0.01010101\n",
      "  0.          0.          0.002886    0.          0.004329    0.00577201\n",
      "  0.001443    0.002886    0.          0.001443    0.001443    0.          0.001443\n",
      "  0.          0.001443    0.004329    0.          0.001443    0.          0.\n",
      "  0.          0.001443    0.002886    0.00865801  0.001443    0.          0.\n",
      "  0.00721501  0.00721501  0.          0.          0.001443    0.001443\n",
      "  0.001443    0.001443    0.004329    0.          0.          0.002886    0.\n",
      "  0.002886    0.002886    0.          0.004329    0.001443    0.002886\n",
      "  0.001443    0.          0.          0.          0.004329    0.001443    0.\n",
      "  0.00577201  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.001443    0.          0.001443    0.001443    0.\n",
      "  0.          0.          0.          0.          0.00721501  0.          0.\n",
      "  0.          0.001443    0.          0.          0.004329    0.002886    0.\n",
      "  0.          0.001443    0.002886    0.          0.001443    0.\n",
      "  0.01010101  0.          0.00577201  0.          0.          0.001443    0.\n",
      "  0.          0.          0.002886    0.001443    0.001443    0.001443    0.\n",
      "  0.          0.001443    0.          0.          0.001443    0.          0.004329\n",
      "  0.          0.          0.002886    0.00721501  0.          0.002886\n",
      "  0.001443    0.001443    0.          0.          0.001443    0.00865801\n",
      "  0.          0.001443    0.001443    0.004329    0.          0.001443    0.\n",
      "  0.001443    0.          0.          0.001443    0.          0.001443\n",
      "  0.01010101  0.          0.          0.002886    0.001443    0.          0.\n",
      "  0.          0.001443    0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.001443    0.          0.\n",
      "  0.          0.          0.          0.          0.01298701  0.          0.\n",
      "  0.001443    0.00721501  0.001443    0.00865801  0.          0.004329    0.\n",
      "  0.          0.          0.004329    0.          0.          0.          0.001443\n",
      "  0.          0.00577201  0.001443    0.004329    0.001443    0.00577201\n",
      "  0.          0.          0.          0.004329    0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01010101  0.          0.          0.002886    0.          0.          0.004329\n",
      "  0.          0.001443    0.          0.001443    0.          0.001443    0.\n",
      "  0.001443    0.          0.004329    0.          0.          0.          0.001443\n",
      "  0.          0.          0.          0.          0.001443    0.          0.\n",
      "  0.          0.          0.001443    0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Accuracy: 71.91%\n"
     ]
    }
   ],
   "source": [
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()\n",
    "print(model.feature_importances_)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(test_X)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(test_Y, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12772L, 864L)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n",
      "Thresh=0.000, n=864, Accuracy: 71.91%\n"
     ]
    }
   ],
   "source": [
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(train_X)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier()\n",
    "\tselection_model.fit(select_X_train, train_Y)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(test_X)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(test_Y, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "print(sklearn.metrics.accuracy_score(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(sklearn.metrics.classification_report(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(test_Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "zero_one_loss(test_Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr,tpr,thresh = roc_curve(test_Y, y_pred)\n",
    "plt.plot(fpr,tpr,[0,1],[0,1],\"--\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the iris datasets\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 20)\n",
    "rfe = rfe.fit(train_X, train_Y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
