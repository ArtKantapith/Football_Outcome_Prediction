{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "\n",
    "features = 'potential,attacking_work_rate,defensive_work_rate,crossing,finishing,heading_accuracy,short_passing,volleys,dribbling,curve,free_kick_accuracy,long_passing,ball_control,acceleration,sprint_speed,agility,reactions,balance,shot_power,jumping,stamina,strength,long_shots,aggression,interceptions,positioning,vision,penalties,marking,standing_tackle,sliding_tackle,gk_diving,gk_handling,gk_kicking,gk_positioning,gk_reflexes'\n",
    "features_list = features.split(',')\n",
    "num_features = len(features_list)\n",
    "features_list = features_list * 30\n",
    "\n",
    "print(len(features_list))\n",
    "k=0\n",
    "for bucket_id in range(30):\n",
    "    idx = bucket_id  * num_features\n",
    "    for feature in features_list[ bucket_id  * num_features :  (bucket_id + 1 ) * num_features]:\n",
    "\n",
    "        features_list[idx] = str(bucket_id) + \"_\" + features_list[idx]\n",
    "        idx += 1\n",
    "\n",
    "print features_list\n",
    "\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=0, seed=100):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.ix[perm[:train_end]]\n",
    "    validate = df.ix[perm[train_end:validate_end]]\n",
    "    test = df.ix[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "outfile = 'alldata_buckets_4x3.npz'\n",
    "npzfile = np.load(outfile)\n",
    "print npzfile.files\n",
    "all_data = npzfile['arr_0']\n",
    "print(all_data.shape)\n",
    "\n",
    "train_data, validate_data, test_data = train_validate_test_split(pd.DataFrame(all_data))\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "validate_data = np.array(validate_data)\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "\n",
    "train_X = train_data[:, :-1]\n",
    "\n",
    "validate_X = validate_data[:, :-1]\n",
    "test_X = test_data[:, :-1]\n",
    "train_Y = train_data[:,-1]\n",
    "validate_Y = validate_data[:,-1]\n",
    "test_Y = test_data[:,-1]\n",
    "print(train_X.shape)\n",
    "print(validate_X.shape)\n",
    "print(test_X.shape)\n",
    "\n",
    "epsilon = 1e-12\n",
    "mean_train = np.mean(train_X, axis = 0)\n",
    "std_train = np.std(train_X, axis = 0) + epsilon\n",
    "train_X = (train_X - mean_train)/std_train\n",
    "test_X = (test_X - mean_train)/std_train\n",
    "\n",
    "kbest = sklearn.linear_model.LogisticRegression(penalty='l1', C= 5)\n",
    "kbest.fit(train_X, train_Y)\n",
    "print('training accuracy', kbest.score(train_X, train_Y))\n",
    "print('test accuracy', kbest.score(test_X, test_Y))\n",
    "print('all coefficients', kbest.coef_)\n",
    "best_features = np.argsort(np.abs(kbest.coef_))[::-1].reshape(1080*2)\n",
    "#print('15 best features', best_features)\n",
    "coefs = kbest.coef_\n",
    "coefs = coefs.reshape(1080*2)\n",
    "print(best_features.shape)\n",
    "for idx, _ in  enumerate(coefs):\n",
    "    print features_list[idx], \",\", coefs[idx]\n",
    "\n",
    "'''\n",
    "import sklearn.ensemble\n",
    "\n",
    "random_forest = sklearn.ensemble.RandomForestClassifier(n_estimators=10)\n",
    "random_forest.fit_transform(train_X, train_Y)\n",
    "print('training accuracy', random_forest.score(train_X, train_Y))\n",
    "print('test accuracy', random_forest.score(test_X, test_Y))\n",
    "print('random_forest features', random_forest.feature_importances_)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(clf, train_X, train_Y, cv=10)\n",
    "print(\"Decision tree accuracy\" , cross_val_score(clf, test_X, test_Y, cv=10))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "train_mean = np.mean(train_X, axis = 0)\n",
    "train_std = np.std(train_X, axis=0)\n",
    "train_X = (train_X - train_mean)/train_std\n",
    "test_X = (test_X  - train_mean)/train_std\n",
    "\n",
    "pca.fit_transform(train_X)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "#test_X = pca.transform(test_X)\n",
    "kbest = sklearn.linear_model.LogisticRegression()\n",
    "kbest.fit_transform(train_X, train_Y)\n",
    "print('training accuracy after pca', kbest.score(train_X, train_Y))\n",
    "print('test accuracy after ', kbest.score(test_X, test_Y))\n",
    "print('all coefficients after pca', kbest.coef_)\n",
    "best_features = np.argsort(np.abs(kbest.coef_))[::-1].reshape(144)\n",
    "#print('15 best features', best_features)\n",
    "print(best_features.shape)\n",
    "for idx in  best_features:\n",
    "    print features_list[idx]\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_X, train_Y)\n",
    "preds = clf.predict(test_X)\n",
    "mask = np.ones(test_Y.shape[0])\n",
    "print(np.sum(mask[preds == test_Y]))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}